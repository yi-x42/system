"""
YOLOv11 æ¨¡å‹è³‡è¨Šæå–å·¥å…·
åˆ†ææ¨¡å‹æ–‡ä»¶çš„è©³ç´°è³‡è¨Š
"""
import torch
import os
from pathlib import Path
import json

def extract_model_info(model_path):
    """æå– YOLO æ¨¡å‹çš„è©³ç´°è³‡è¨Š"""
    try:
        model_path = Path(model_path)
        if not model_path.exists():
            return {"error": f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}"}
        
        print(f"ğŸ“ åˆ†ææ¨¡å‹æ–‡ä»¶: {model_path}")
        print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {model_path.stat().st_size / (1024*1024):.1f} MB")
        
        # è¼‰å…¥æ¨¡å‹æª¢æŸ¥é» (è™•ç† YOLO æ¨¡å‹çš„å®‰å…¨è¼‰å…¥)
        try:
            # å˜—è©¦å®‰å…¨è¼‰å…¥
            checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
        except Exception as e1:
            print(f"âš ï¸ æ¨™æº–è¼‰å…¥å¤±æ•—: {e1}")
            try:
                # å˜—è©¦å…è¨± ultralytics å…¨åŸŸ
                import torch.serialization
                torch.serialization.add_safe_globals(['ultralytics.nn.tasks.DetectionModel'])
                checkpoint = torch.load(model_path, map_location='cpu')
            except Exception as e2:
                print(f"âš ï¸ å®‰å…¨è¼‰å…¥å¤±æ•—: {e2}")
                # æœ€å¾Œå˜—è©¦ä¸å®‰å…¨è¼‰å…¥ (åƒ…ç”¨æ–¼åˆ†æ)
                checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
        
        model_info = {
            "file_size_mb": round(model_path.stat().st_size / (1024*1024), 1),
            "file_path": str(model_path)
        }
        
        print(f"ğŸ” æª¢æŸ¥é»é¡å‹: {type(checkpoint)}")
        
        if isinstance(checkpoint, dict):
            print(f"ğŸ“‹ æª¢æŸ¥é»åŒ…å«çš„éµ: {list(checkpoint.keys())}")
            
            # æ¨¡å‹æ¶æ§‹è³‡è¨Š
            if 'model' in checkpoint:
                model = checkpoint['model']
                print(f"ğŸ—ï¸ æ¨¡å‹é¡å‹: {type(model)}")
                
                # è¨ˆç®—åƒæ•¸é‡
                if hasattr(model, 'parameters'):
                    total_params = sum(p.numel() for p in model.parameters())
                    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
                    model_info['total_parameters'] = total_params
                    model_info['trainable_parameters'] = trainable_params
                    model_info['parameters_m'] = f"{total_params/1e6:.1f}M"
                    print(f"âš™ï¸ ç¸½åƒæ•¸é‡: {total_params:,} ({total_params/1e6:.1f}M)")
                    print(f"ğŸ¯ å¯è¨“ç·´åƒæ•¸: {trainable_params:,}")
                
                # é¡åˆ¥è³‡è¨Š
                if hasattr(model, 'names') and model.names:
                    model_info['class_names'] = model.names
                    model_info['num_classes'] = len(model.names)
                    print(f"ğŸ·ï¸ é¡åˆ¥æ•¸é‡: {len(model.names)}")
                    print(f"ğŸ“ é¡åˆ¥åç¨±: {list(model.names.values())[:10]}..." if len(model.names) > 10 else f"ğŸ“ é¡åˆ¥åç¨±: {list(model.names.values())}")
                
                # æ¨¡å‹é…ç½®
                if hasattr(model, 'yaml'):
                    model_info['yaml_config'] = model.yaml
                    print(f"ğŸ“„ YAML é…ç½®: å¯ç”¨")
                
                if hasattr(model, 'model') and hasattr(model.model, '__len__'):
                    model_info['num_layers'] = len(model.model)
                    print(f"ğŸ”— å±¤æ•¸: {len(model.model)}")
            
            # è¨“ç·´è³‡è¨Š
            if 'epoch' in checkpoint:
                model_info['trained_epochs'] = checkpoint['epoch']
                print(f"ğŸ“ˆ è¨“ç·´é€±æœŸ: {checkpoint['epoch']}")
            
            if 'best_fitness' in checkpoint:
                model_info['best_fitness'] = float(checkpoint['best_fitness'])
                print(f"ğŸ† æœ€ä½³é©æ‡‰åº¦: {checkpoint['best_fitness']}")
            
            # æ€§èƒ½æŒ‡æ¨™
            metrics_keys = ['metrics', 'results', 'best_fitness']
            for key in metrics_keys:
                if key in checkpoint:
                    model_info[key] = checkpoint[key]
                    print(f"ğŸ“Š {key}: å¯ç”¨")
            
            # å…ƒæ•¸æ“š
            metadata_keys = ['date', 'version', 'license', 'docs', 'imgsz', 'task']
            for key in metadata_keys:
                if key in checkpoint:
                    model_info[key] = checkpoint[key]
                    print(f"â„¹ï¸ {key}: {checkpoint[key]}")
        
        return model_info
        
    except Exception as e:
        return {"error": f"è¼‰å…¥æ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"}

def main():
    print("=" * 60)
    print("ğŸ” YOLOv11n æ¨¡å‹è©³ç´°è³‡è¨Šåˆ†æ")
    print("=" * 60)
    
    model_path = r"D:\project\system\yolo11n.pt"
    info = extract_model_info(model_path)
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ åˆ†æçµæœç¸½çµ")
    print("=" * 60)
    
    if "error" in info:
        print(f"âŒ éŒ¯èª¤: {info['error']}")
    else:
        # æ•´ç†é—œéµè³‡è¨Š
        print(f"ğŸ“ æ–‡ä»¶å¤§å°: {info.get('file_size_mb', 'N/A')} MB")
        print(f"âš™ï¸ åƒæ•¸é‡: {info.get('parameters_m', 'N/A')}")
        print(f"ğŸ·ï¸ é¡åˆ¥æ•¸: {info.get('num_classes', 'N/A')}")
        print(f"ğŸ”— å±¤æ•¸: {info.get('num_layers', 'N/A')}")
        print(f"ğŸ“ˆ è¨“ç·´é€±æœŸ: {info.get('trained_epochs', 'N/A')}")
        print(f"ğŸ† æœ€ä½³é©æ‡‰åº¦: {info.get('best_fitness', 'N/A')}")
        
        # ä¿å­˜è©³ç´°è³‡è¨Šåˆ° JSON
        output_file = "yolov11n_model_info.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(info, f, ensure_ascii=False, indent=2, default=str)
        print(f"\nğŸ’¾ è©³ç´°è³‡è¨Šå·²ä¿å­˜åˆ°: {output_file}")

if __name__ == "__main__":
    main()
