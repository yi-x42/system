"""
ç›´æ¥æª¢æ¸¬æ¸¬è©¦å·¥å…· - ç”¨æ–¼è¨ºæ–·YOLOæª¢æ¸¬å•é¡Œ
"""

import cv2
import numpy as np
import os
import sys
import time
from pathlib import Path

# æ·»åŠ è·¯å¾‘
sys.path.append(str(Path(__file__).parent))

def test_direct_yolo():
    """ç›´æ¥æ¸¬è©¦YOLOæª¢æ¸¬"""
    print("ğŸš€ é–‹å§‹ç›´æ¥YOLOæª¢æ¸¬æ¸¬è©¦")
    print("=" * 50)
    
    try:
        # å°å…¥YOLO
        from ultralytics import YOLO
        print("âœ… YOLOå°å…¥æˆåŠŸ")
        
        # æª¢æŸ¥æ¨¡å‹æª”æ¡ˆ
        model_path = "yolo11n.pt"
        if not os.path.exists(model_path):
            print(f"ğŸ“¥ ä¸‹è¼‰æ¨¡å‹: {model_path}")
            model = YOLO(model_path)  # æœƒè‡ªå‹•ä¸‹è¼‰
        else:
            print(f"âœ… æ¨¡å‹å­˜åœ¨: {model_path}")
            model = YOLO(model_path)
        
        print("âœ… YOLOæ¨¡å‹è¼‰å…¥æˆåŠŸ")
        print(f"ğŸ“‹ æ¨¡å‹é¡åˆ¥æ•¸: {len(model.names)}")
        print(f"ğŸ“‹ å‰10å€‹é¡åˆ¥: {list(model.names.values())[:10]}")
        
        # æ¸¬è©¦æ”å½±æ©Ÿ
        print("\nğŸ“· æ¸¬è©¦æ”å½±æ©Ÿ...")
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            print("âŒ ç„¡æ³•é–‹å•Ÿæ”å½±æ©Ÿ")
            return
            
        # è¨­å®šæ”å½±æ©Ÿå±¬æ€§
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        cap.set(cv2.CAP_PROP_FPS, 30)
        
        print("âœ… æ”å½±æ©Ÿé–‹å•ŸæˆåŠŸ")
        
        # é€£çºŒæª¢æ¸¬å¹¾å¹€
        print("\nğŸ” é–‹å§‹é€£çºŒæª¢æ¸¬æ¸¬è©¦...")
        for i in range(10):
            ret, frame = cap.read()
            if not ret:
                print(f"âŒ ç¬¬{i+1}å¹€ç²å–å¤±æ•—")
                continue
                
            print(f"ğŸ“¸ ç¬¬{i+1}å¹€: {frame.shape}")
            
            # é€²è¡Œæª¢æ¸¬ - ä½¿ç”¨å¤šå€‹ä¿¡å¿ƒåº¦é–¾å€¼
            for conf in [0.05, 0.1, 0.25, 0.5]:
                start_time = time.time()
                results = model(frame, conf=conf, verbose=False)
                inference_time = time.time() - start_time
                
                detections = results[0].boxes
                if detections is not None and len(detections) > 0:
                    print(f"  âœ… ä¿¡å¿ƒåº¦{conf}: æª¢æ¸¬åˆ°{len(detections)}å€‹ç‰©ä»¶ (æ¨è«–æ™‚é–“: {inference_time:.3f}s)")
                    for j, detection in enumerate(detections):
                        conf_score = detection.conf.item()
                        cls = int(detection.cls.item())
                        class_name = model.names.get(cls, f"class_{cls}")
                        bbox = detection.xyxy[0].tolist()
                        print(f"    {j+1}. {class_name} ({conf_score:.3f}) [{bbox[0]:.0f},{bbox[1]:.0f},{bbox[2]:.0f},{bbox[3]:.0f}]")
                else:
                    print(f"  âŒ ä¿¡å¿ƒåº¦{conf}: æœªæª¢æ¸¬åˆ°ç‰©ä»¶")
            
            time.sleep(0.5)
        
        # å‰µå»ºæ¸¬è©¦åœ–åƒ
        print("\nğŸ¨ æ¸¬è©¦åˆæˆåœ–åƒ...")
        test_img = create_test_image_with_objects()
        
        for conf in [0.05, 0.1, 0.25, 0.5]:
            results = model(test_img, conf=conf, verbose=False)
            detections = results[0].boxes
            if detections is not None and len(detections) > 0:
                print(f"âœ… åˆæˆåœ–åƒ ä¿¡å¿ƒåº¦{conf}: æª¢æ¸¬åˆ°{len(detections)}å€‹ç‰©ä»¶")
                for j, detection in enumerate(detections):
                    conf_score = detection.conf.item()
                    cls = int(detection.cls.item())
                    class_name = model.names.get(cls, f"class_{cls}")
                    print(f"  {j+1}. {class_name} ({conf_score:.3f})")
            else:
                print(f"âŒ åˆæˆåœ–åƒ ä¿¡å¿ƒåº¦{conf}: æœªæª¢æ¸¬åˆ°ç‰©ä»¶")
        
        cap.release()
        print("\nâœ… æ¸¬è©¦å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

def create_test_image_with_objects():
    """å‰µå»ºåŒ…å«æ˜é¡¯ç‰©ä»¶çš„æ¸¬è©¦åœ–åƒ"""
    # å‰µå»ºç™½åº•åœ–åƒ
    img = np.ones((480, 640, 3), dtype=np.uint8) * 255
    
    # ç¹ªè£½é¡ä¼¼æ‰‹æ©Ÿçš„çŸ©å½¢ (é»‘è‰²)
    cv2.rectangle(img, (100, 150), (250, 400), (0, 0, 0), -1)
    cv2.rectangle(img, (110, 160), (240, 190), (100, 100, 100), -1)  # è¢å¹•
    
    # ç¹ªè£½é¡ä¼¼æ¯å­çš„åœ“å½¢ (è—è‰²)
    cv2.circle(img, (450, 300), 60, (255, 0, 0), -1)
    cv2.circle(img, (450, 300), 50, (200, 200, 200), -1)
    
    # ç¹ªè£½é¡ä¼¼æ›¸æœ¬çš„çŸ©å½¢ (ç¶ è‰²)
    cv2.rectangle(img, (300, 100), (500, 200), (0, 255, 0), -1)
    cv2.line(img, (300, 150), (500, 150), (0, 200, 0), 3)
    
    # æ·»åŠ ä¸€äº›ç´‹ç†
    cv2.putText(img, "TEST", (320, 160), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
    
    return img

def test_camera_only():
    """åƒ…æ¸¬è©¦æ”å½±æ©Ÿ"""
    print("ğŸ“· æ”å½±æ©ŸåŠŸèƒ½æ¸¬è©¦")
    cap = cv2.VideoCapture(0)
    
    if not cap.isOpened():
        print("âŒ æ”å½±æ©Ÿç„¡æ³•é–‹å•Ÿ")
        return False
        
    for i in range(5):
        ret, frame = cap.read()
        if ret:
            print(f"âœ… ç¬¬{i+1}å¹€: {frame.shape}, åƒç´ ç¯„åœ: {frame.min()}-{frame.max()}")
        else:
            print(f"âŒ ç¬¬{i+1}å¹€ç²å–å¤±æ•—")
        time.sleep(0.2)
    
    cap.release()
    return True

if __name__ == "__main__":
    print("ğŸ”§ YOLOæª¢æ¸¬è¨ºæ–·å·¥å…·")
    print("=" * 50)
    
    # å…ˆæ¸¬è©¦æ”å½±æ©Ÿ
    if test_camera_only():
        print("\n" + "=" * 50)
        # å†æ¸¬è©¦YOLO
        test_direct_yolo()
    else:
        print("âŒ æ”å½±æ©Ÿæ¸¬è©¦å¤±æ•—ï¼Œåœæ­¢å¾ŒçºŒæ¸¬è©¦")
